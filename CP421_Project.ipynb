{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8XoGbxtbL2_",
        "outputId": "68b0ee30-007b-46d2-c2d0-ebc86af5e38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading book-recommendation-dataset.zip to /content\n",
            " 90% 22.0M/24.3M [00:00<00:00, 72.2MB/s]\n",
            "100% 24.3M/24.3M [00:00<00:00, 69.9MB/s]\n",
            "Archive:  book-recommendation-dataset.zip\n",
            "  inflating: Books.csv               \n",
            "  inflating: DeepRec.png             \n",
            "  inflating: Ratings.csv             \n",
            "  inflating: Users.csv               \n",
            "  inflating: classicRec.png          \n",
            "  inflating: recsys_taxonomy2.png    \n",
            "book-recommendation-dataset.zip  classicRec.png  Ratings.csv\t       sample_data\n",
            "Books.csv\t\t\t DeepRec.png\t recsys_taxonomy2.png  Users.csv\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d arashnic/book-recommendation-dataset\n",
        "!unzip book-recommendation-dataset.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from scipy.sparse import csr_matrix, vstack\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import scipy.sparse as sp\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "7bR4fur4Aq-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHwLU_pdCKF5",
        "outputId": "47964ae1-d3f6-4c7f-d29f-60f1b561180a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-38abf8a8d748>:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  books = pd.read_csv('Books.csv', delimiter=',', encoding='ISO-8859-1')\n"
          ]
        }
      ],
      "source": [
        "# Load the datasets\n",
        "users = pd.read_csv('Users.csv', delimiter=',', encoding='ISO-8859-1')\n",
        "books = pd.read_csv('Books.csv', delimiter=',', encoding='ISO-8859-1')\n",
        "ratings = pd.read_csv('Ratings.csv', delimiter=',', encoding='ISO-8859-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mmLiEtAlliT"
      },
      "outputs": [],
      "source": [
        "# Handle missing or invalid Age\n",
        "users['Age'] = pd.to_numeric(users['Age'], errors='coerce')  # Convert to numeric, invalid entries become NaN\n",
        "users.loc[(users['Age'] < 5) | (users['Age'] > 100), 'Age'] = np.nan  # Replace unrealistic ages with NaN\n",
        "median_age = users['Age'].median()\n",
        "users['Age'] = users['Age'].fillna(median_age)  # Fill missing ages with median\n",
        "\n",
        "# Split Location into City, State, and Country\n",
        "location_split = users['Location'].str.split(',', expand=True)\n",
        "users['City'] = location_split[0].str.strip()  # Extract City\n",
        "users['State'] = location_split[1].str.strip() if location_split.shape[1] > 1 else np.nan  # Extract State\n",
        "users['Country'] = location_split[2].str.strip() if location_split.shape[1] > 2 else np.nan  # Extract Country\n",
        "\n",
        "# Handle missing or inconsistent location data\n",
        "users['Country'] = users['Country'].fillna('Unknown')  # Replace missing countries with 'Unknown'\n",
        "\n",
        "encoder_country = LabelEncoder()\n",
        "users['Country-Encoded'] = encoder_country.fit_transform(users['Country'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxxkUI85ll1l"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary image URL columns from books\n",
        "books = books.drop(columns=['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], errors='ignore')\n",
        "\n",
        "# Replace invalid years with NaN and then fill with median\n",
        "books['Year-Of-Publication'] = pd.to_numeric(books['Year-Of-Publication'], errors='coerce')\n",
        "median_year = books['Year-Of-Publication'].median()\n",
        "books['Year-Of-Publication'] = books['Year-Of-Publication'].fillna(median_year)\n",
        "\n",
        "# Normalize Year-Of-Publication\n",
        "scaler = MinMaxScaler()\n",
        "books[['Year-Of-Publication']] = scaler.fit_transform(books[['Year-Of-Publication']])\n",
        "\n",
        "# Encode Book-Author and Publisher\n",
        "encoder_author = LabelEncoder()\n",
        "books['Book-Author-Encoded'] = encoder_author.fit_transform(books['Book-Author'])\n",
        "\n",
        "encoder_publisher = LabelEncoder()\n",
        "books['Publisher-Encoded'] = encoder_publisher.fit_transform(books['Publisher'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti5u3KPspwag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93586bde-f714-40fc-d5fe-985da83d0fbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-7a4bfa179360>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  explicit_ratings['Normalized-Rating'] = explicit_ratings.groupby('User-ID')['Book-Rating'].transform(\n"
          ]
        }
      ],
      "source": [
        "# Ensure Book-Rating is an integer and within the valid range (0-10)\n",
        "ratings['Book-Rating'] = pd.to_numeric(ratings['Book-Rating'], errors='coerce')\n",
        "ratings = ratings[(ratings['Book-Rating'] >= 0) & (ratings['Book-Rating'] <= 10)]\n",
        "\n",
        "# Handle implicit and explicit interactions\n",
        "explicit_ratings = ratings[ratings['Book-Rating'] > 0]\n",
        "implicit_interactions = ratings[ratings['Book-Rating'] == 0]\n",
        "\n",
        "# Normalize explicit ratings per user\n",
        "explicit_ratings['Normalized-Rating'] = explicit_ratings.groupby('User-ID')['Book-Rating'].transform(\n",
        "    lambda x: x - x.mean()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8f3Q5uqvOPA",
        "outputId": "f70acb48-327f-4780-98f9-19d107da8e6d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users Data:\n",
            "   User-ID                            Location   Age         City  \\\n",
            "0        1                  nyc, new york, usa  32.0          nyc   \n",
            "1        2           stockton, california, usa  18.0     stockton   \n",
            "2        3     moscow, yukon territory, russia  32.0       moscow   \n",
            "3        4           porto, v.n.gaia, portugal  17.0        porto   \n",
            "4        5  farnborough, hants, united kingdom  32.0  farnborough   \n",
            "\n",
            "             State         Country  Country-Encoded  \n",
            "0         new york             usa             1001  \n",
            "1       california             usa             1001  \n",
            "2  yukon territory          russia              811  \n",
            "3         v.n.gaia        portugal              763  \n",
            "4            hants  united kingdom              984   \n",
            "\n",
            "Books Data:\n",
            "         ISBN                                         Book-Title  \\\n",
            "0  0195153448                                Classical Mythology   \n",
            "1  0002005018                                       Clara Callan   \n",
            "2  0060973129                               Decision in Normandy   \n",
            "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
            "4  0393045218                             The Mummies of Urumchi   \n",
            "\n",
            "            Book-Author  Year-Of-Publication                   Publisher  \\\n",
            "0    Mark P. O. Morford             0.976585     Oxford University Press   \n",
            "1  Richard Bruce Wright             0.976098       HarperFlamingo Canada   \n",
            "2          Carlo D'Este             0.971220             HarperPerennial   \n",
            "3      Gina Bari Kolata             0.975122        Farrar Straus Giroux   \n",
            "4       E. J. W. Barber             0.975122  W. W. Norton &amp; Company   \n",
            "\n",
            "   Book-Author-Encoded  Publisher-Encoded  \n",
            "0                65201              10973  \n",
            "1                81480               6666  \n",
            "2                12670               6669  \n",
            "3                34303               5291  \n",
            "4                25094              15843   \n",
            "\n",
            "Ratings Data:\n",
            "   User-ID        ISBN  Book-Rating\n",
            "0   276725  034545104X            0\n",
            "1   276726  0155061224            5\n",
            "2   276727  0446520802            0\n",
            "3   276729  052165615X            3\n",
            "4   276729  0521795028            6 \n",
            "\n",
            "Explicit Data:\n",
            "   User-ID        ISBN  Book-Rating  Normalized-Rating\n",
            "1   276726  0155061224            5                0.0\n",
            "3   276729  052165615X            3               -1.5\n",
            "4   276729  0521795028            6                1.5\n",
            "6   276736  3257224281            8                0.0\n",
            "7   276737  0600570967            6                0.0 \n",
            "\n",
            "Implicit Data:\n",
            "    User-ID        ISBN  Book-Rating\n",
            "0    276725  034545104X            0\n",
            "2    276727  0446520802            0\n",
            "5    276733  2080674722            0\n",
            "10   276746  0425115801            0\n",
            "11   276746  0449006522            0 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print Dataset\n",
        "print(\"Users Data:\")\n",
        "print(users.head(), \"\\n\")\n",
        "print(\"Books Data:\")\n",
        "print(books.head(), \"\\n\")\n",
        "print(\"Ratings Data:\")\n",
        "print(ratings.head(), \"\\n\")\n",
        "print(\"Explicit Data:\")\n",
        "print(explicit_ratings.head(), \"\\n\")\n",
        "print(\"Implicit Data:\")\n",
        "print(implicit_interactions.head(), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5WOWsIarJ40",
        "outputId": "97038048-5089-4b37-f1da-042e8f5e130e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Matrix Shape: (383842, 38792)\n",
            "Reduced Matrix Shape: (383842, 700)\n",
            "Top 5 recommendations for Book ISBN 0002005018:         ISBN                                       Book-Title  \\\n",
            "0  3551551685       Harry Potter und die Kammer des Schreckens   \n",
            "1  0684846608                       Fountain Society : A NOVEL   \n",
            "2  0836221192         Dilbert Fugitive From The Cubicle Police   \n",
            "3  3608932240  Der Herr der Ringe. AnhÃ?ÃÂ¤nge und Register.   \n",
            "4  0671032658                                   The Green Mile   \n",
            "\n",
            "                 Book-Author  \n",
            "0          Joanne K. Rowling  \n",
            "1                 Wes Craven  \n",
            "2                Scott Adams  \n",
            "3  John Ronald Reuel Tolkien  \n",
            "4               Stephen King  \n"
          ]
        }
      ],
      "source": [
        "#Content Based Filtering\n",
        "# Merge Explicit Ratings with Books\n",
        "merged = explicit_ratings.merge(books, on='ISBN', how='inner')\n",
        "\n",
        "# Combine Features\n",
        "merged['Combined-Features'] = (\n",
        "    merged['Book-Author'].astype(str) + ' ' +\n",
        "    merged['Publisher'].astype(str) + ' ' +\n",
        "    merged['Year-Of-Publication'].astype(str)\n",
        ")\n",
        "\n",
        "# Vectorize Combined Features\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "feature_matrix = tfidf.fit_transform(merged['Combined-Features'])\n",
        "\n",
        "\n",
        "# Reduce Dimensions with Truncated SVD\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "svd = TruncatedSVD(n_components=700, random_state=42)  # Retain 700 components\n",
        "reduced_matrix = svd.fit_transform(feature_matrix)\n",
        "\n",
        "\n",
        "# Check matrix shapes\n",
        "print(\"Feature Matrix Shape:\", feature_matrix.shape)\n",
        "print(\"Reduced Matrix Shape:\", reduced_matrix.shape)\n",
        "\n",
        "# Function to Recommend Books Based on Similarity\n",
        "def recommend_books_by_content(book_isbn, top_n=5):\n",
        "    if book_isbn not in merged['ISBN'].values:\n",
        "        return \"Book not found in the dataset.\"\n",
        "\n",
        "    book_index = merged[merged['ISBN'] == book_isbn].index[0]\n",
        "\n",
        "    # Get similarity scores for this book\n",
        "    similarity_scores = list(enumerate(reduced_matrix[book_index]))\n",
        "\n",
        "    # Sort by similarity score in descending order\n",
        "    sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the indices of top N similar books (excluding the current book)\n",
        "    top_indices = [idx for idx, score in sorted_scores[1:top_n + 1]]\n",
        "\n",
        "    # Fetch the details of recommended books\n",
        "    recommended_books = merged.iloc[top_indices][['ISBN', 'Book-Title', 'Book-Author']].drop_duplicates()\n",
        "    return recommended_books.reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "book_isbn = '0002005018'\n",
        "top_recommendations = recommend_books_by_content(book_isbn, top_n=5)\n",
        "\n",
        "print(f\"Top 5 recommendations for Book ISBN {book_isbn}:{top_recommendations}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_books_by_content_updated(book_isbn, top_n=5):\n",
        "    if book_isbn not in merged['ISBN'].values:\n",
        "        return \"Book not found in the dataset.\"\n",
        "\n",
        "    book_index = merged[merged['ISBN'] == book_isbn].index[0]\n",
        "\n",
        "    # Get similarity scores for this book\n",
        "    similarity_scores = list(enumerate(reduced_matrix[book_index]))\n",
        "\n",
        "    # Sort by similarity score in descending order\n",
        "    sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the indices of top N similar books (excluding the current book)\n",
        "    top_indices = [idx for idx, score in sorted_scores[1:top_n + 1]]\n",
        "\n",
        "    # Fetch the ISBNs of recommended books\n",
        "    recommended_isbns = merged.iloc[top_indices]['ISBN'].drop_duplicates().tolist()\n",
        "    return recommended_isbns\n",
        "\n",
        "def evaluate_svd_performance(merged, components_list, book_isbn, true_recommendations, top_n=5):\n",
        "    results = []\n",
        "\n",
        "    # Combine features\n",
        "    merged['Combined-Features'] = (\n",
        "        merged['Book-Author'].astype(str) + ' ' +\n",
        "        merged['Publisher'].astype(str) + ' ' +\n",
        "        merged['Year-Of-Publication'].astype(str)\n",
        "    )\n",
        "\n",
        "    # Vectorize features\n",
        "    tfidf = TfidfVectorizer(stop_words='english')\n",
        "    feature_matrix = tfidf.fit_transform(merged['Combined-Features'])\n",
        "\n",
        "    for n_components in components_list:\n",
        "        # Reduce dimensions with Truncated SVD\n",
        "        svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
        "        reduced_matrix = svd.fit_transform(feature_matrix)\n",
        "\n",
        "        # Get recommendations\n",
        "        predicted_recommendations = recommend_books_by_content_updated(book_isbn, top_n=top_n)\n",
        "\n",
        "\n",
        "\n",
        "        # Evaluate accuracy\n",
        "        y_true = [1 if isbn in true_recommendations else 0 for isbn in merged['ISBN'].values]\n",
        "        y_pred = [1 if isbn in predicted_recommendations else 0 for isbn in merged['ISBN'].values]\n",
        "\n",
        "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "        results.append({\n",
        "            'Components': n_components,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1-Score': f1\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "true_recommendations = ['3551551685', '0684846608', '0836221192','3608932240','0671032658']\n",
        "components_list = [100,400, 700, 900]\n",
        "\n",
        "# Evaluate and display results\n",
        "results_df = evaluate_svd_performance(merged, components_list, '0002005018', true_recommendations)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9_8dgLkEs7O",
        "outputId": "51149186-cf7a-4f11-b703-83c69bce08d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Components  Precision  Recall  F1-Score\n",
            "0         100   0.076190     1.0  0.141593\n",
            "1         400   0.933333     1.0  0.965517\n",
            "2         700   1.000000     1.0  1.000000\n",
            "3         900   0.885714     1.0  0.939394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrFC7eyseqwm",
        "outputId": "bc5cb202-1857-44e3-c1fa-cc67aaa71e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 book recommendations for User ID 276726:\n",
            "         ISBN  Predicted-Rating\n",
            "0  2020564777          0.940958\n",
            "1  0684867621          0.770394\n",
            "2  2253030570          0.670831\n",
            "3  2070386023          0.642721\n",
            "4  2070404587          0.588241\n"
          ]
        }
      ],
      "source": [
        "def recommend_books_for_user_content(user_id, top_n=5):\n",
        "    if user_id not in explicit_ratings['User-ID'].values:\n",
        "        return f\"User ID {user_id} not found in the dataset.\"\n",
        "\n",
        "    # Get books rated by the user\n",
        "    user_ratings = explicit_ratings[explicit_ratings['User-ID'] == user_id]\n",
        "\n",
        "    # Identify the top-liked book by the user\n",
        "    top_rated_book_isbn = user_ratings.loc[user_ratings['Book-Rating'].idxmax(), 'ISBN']\n",
        "\n",
        "    #Finding index of the book in merged dataset\n",
        "    if top_rated_book_isbn not in merged['ISBN'].values:\n",
        "        return f\"The user's top-rated book (ISBN {top_rated_book_isbn}) is not in the dataset.\"\n",
        "\n",
        "    book_index = merged[merged['ISBN'] == top_rated_book_isbn].index[0]\n",
        "\n",
        "    # Get similarity scores for this book\n",
        "    similarity_scores = list(enumerate(reduced_matrix[book_index]))\n",
        "\n",
        "    # Sort by similarity score in descending order\n",
        "    sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Collect top recommendations\n",
        "    top_indices = []\n",
        "    predicted_ratings = []\n",
        "    for idx, score in sorted_scores:\n",
        "        if idx != book_index and merged.iloc[idx]['ISBN'] not in user_ratings['ISBN'].values:\n",
        "            top_indices.append(idx)\n",
        "            # Predicted rating based on similarity score\n",
        "            predicted_rating = score * user_ratings['Book-Rating'].max()\n",
        "            predicted_ratings.append((merged.iloc[idx]['ISBN'], predicted_rating))\n",
        "            if len(top_indices) >= top_n:\n",
        "                break\n",
        "\n",
        "    # Create a DataFrame with ISBN and predicted ratings\n",
        "    recommended_books = pd.DataFrame(predicted_ratings, columns=['ISBN', 'Predicted-Rating'])\n",
        "\n",
        "    return recommended_books.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "user_id = 276726\n",
        "top_recommendations_for_user = recommend_books_for_user_content(user_id, top_n=5)\n",
        "\n",
        "print(f\"Top 5 book recommendations for User ID {user_id}:\")\n",
        "print(top_recommendations_for_user)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collaborative Filtering\n",
        "\n",
        "# Merge explicit and implicit ratings\n",
        "ratings = pd.concat([\n",
        "    explicit_ratings[['User-ID', 'ISBN', 'Book-Rating']].rename(columns={'Book-Rating': 'Rating'}),\n",
        "    implicit_interactions[['User-ID', 'ISBN', 'Book-Rating']].rename(columns={'Book-Rating': 'Rating'})\n",
        "], ignore_index=True)\n",
        "\n",
        "# Map user and item IDs to integers for sparse matrix creation\n",
        "user_mapping = {user: i for i, user in enumerate(ratings['User-ID'].unique())}\n",
        "item_mapping = {item: i for i, item in enumerate(ratings['ISBN'].unique())}\n",
        "\n",
        "ratings['User-ID-Mapped'] = ratings['User-ID'].map(user_mapping)\n",
        "ratings['ISBN-Mapped'] = ratings['ISBN'].map(item_mapping)\n",
        "\n",
        "# Split the ratings into training and testing sets\n",
        "train_ratings, test_ratings = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Map user and item IDs for training and test sets\n",
        "train_ratings['User-ID-Mapped'] = train_ratings['User-ID'].map(user_mapping)\n",
        "train_ratings['ISBN-Mapped'] = train_ratings['ISBN'].map(item_mapping)\n",
        "\n",
        "test_ratings['User-ID-Mapped'] = test_ratings['User-ID'].map(user_mapping)\n",
        "test_ratings['ISBN-Mapped'] = test_ratings['ISBN'].map(item_mapping)\n",
        "\n",
        "# Create a sparse user-item matrix for the training set\n",
        "train_sparse = csr_matrix(\n",
        "    (train_ratings['Rating'], (train_ratings['User-ID-Mapped'], train_ratings['ISBN-Mapped']))\n",
        ")\n",
        "\n",
        "# Predict ratings for the test set\n",
        "def predict_rating(user_id, item_id, ipca, user_item_matrix):\n",
        "    if user_id not in user_mapping or item_id not in item_mapping:\n",
        "        return np.nan  # Cannot predict if user/item is not in training data\n",
        "\n",
        "    user_idx = user_mapping[user_id]\n",
        "    item_idx = item_mapping[item_id]\n",
        "\n",
        "    if user_idx >= user_item_matrix.shape[0] or item_idx >= ipca.components_.shape[1]:\n",
        "        return np.nan\n",
        "\n",
        "    # Predict using dot product of reduced components\n",
        "    return user_item_matrix[user_idx].dot(ipca.components_[:, item_idx])"
      ],
      "metadata": {
        "id": "BAM6liqBxnlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating different numbers of latent factors for collaborative filtering"
      ],
      "metadata": {
        "id": "qGPVNuTb4knF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Incremental PCA (acts as Incremental SVD)\n",
        "k = 10  # Number of latent factors\n",
        "batch_size = 50\n",
        "ipca = IncrementalPCA(n_components=k)\n",
        "\n",
        "# Prepare to store results incrementally\n",
        "reduced_chunks_train = []\n",
        "\n",
        "# Fit Incremental PCA on the training set in batches\n",
        "n_samples_train = train_sparse.shape[0]  # Number of users\n",
        "for start in range(0, n_samples_train, batch_size):\n",
        "    end = min(start + batch_size, n_samples_train)\n",
        "    batch = train_sparse[start:end].toarray()  # Convert only the batch to dense\n",
        "\n",
        "    # Skip undersized batches\n",
        "    if batch.shape[0] < k:\n",
        "        print(f\"Skipping undersized batch: {batch.shape[0]} rows, less than k={k}\")\n",
        "        continue\n",
        "\n",
        "    # Incremental fitting\n",
        "    reduced_chunk = ipca.fit_transform(batch) if start == 0 else ipca.transform(batch)\n",
        "    reduced_chunks_train.append(csr_matrix(reduced_chunk))  # Store reduced chunks as sparse matrices\n",
        "\n",
        "# Combine reduced chunks into a sparse matrix\n",
        "user_item_reduced_train = vstack(reduced_chunks_train)\n",
        "\n",
        "# Validate dimensions\n",
        "print(f\"user_item_reduced_train.shape: {user_item_reduced_train.shape}\")\n",
        "print(f\"Vt.T.shape: {ipca.components_.T.shape}\")\n",
        "\n",
        "# Generate predictions for the test set\n",
        "test_ratings['Predicted'] = test_ratings.apply(\n",
        "    lambda row: predict_rating(row['User-ID'], row['ISBN'], ipca, user_item_reduced_train),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Remove NaN predictions\n",
        "test_ratings = test_ratings.dropna(subset=['Predicted'])\n",
        "\n",
        "# Calculate RMSE and MAE\n",
        "rmse = np.sqrt(mean_squared_error(test_ratings['Rating'], test_ratings['Predicted']))\n",
        "mae = mean_absolute_error(test_ratings['Rating'], test_ratings['Predicted'])\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OozxG0W9xL1",
        "outputId": "ac28e8e6-dd95-41dc-fcbe-37e6f21e4104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_item_reduced_train.shape: (105283, 10)\n",
            "Vt.T.shape: (340556, 10)\n",
            "RMSE: 4.8104\n",
            "MAE: 2.8764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Incremental PCA (acts as Incremental SVD)\n",
        "k = 30  # Number of latent factors\n",
        "batch_size = 50\n",
        "ipca = IncrementalPCA(n_components=k)\n",
        "\n",
        "# Prepare to store results incrementally\n",
        "reduced_chunks_train = []\n",
        "\n",
        "# Fit Incremental PCA on the training set in batches\n",
        "n_samples_train = train_sparse.shape[0]  # Number of users\n",
        "for start in range(0, n_samples_train, batch_size):\n",
        "    end = min(start + batch_size, n_samples_train)\n",
        "    batch = train_sparse[start:end].toarray()  # Convert only the batch to dense\n",
        "\n",
        "    # Skip undersized batches\n",
        "    if batch.shape[0] < k:\n",
        "        print(f\"Skipping undersized batch: {batch.shape[0]} rows, less than k={k}\")\n",
        "        continue\n",
        "\n",
        "    # Incremental fitting\n",
        "    reduced_chunk = ipca.fit_transform(batch) if start == 0 else ipca.transform(batch)\n",
        "    reduced_chunks_train.append(csr_matrix(reduced_chunk))  # Store reduced chunks as sparse matrices\n",
        "\n",
        "# Combine reduced chunks into a sparse matrix\n",
        "user_item_reduced_train = vstack(reduced_chunks_train)\n",
        "\n",
        "# Validate dimensions\n",
        "print(f\"user_item_reduced_train.shape: {user_item_reduced_train.shape}\")\n",
        "print(f\"Vt.T.shape: {ipca.components_.T.shape}\")\n",
        "\n",
        "# Generate predictions for the test set\n",
        "test_ratings['Predicted'] = test_ratings.apply(\n",
        "    lambda row: predict_rating(row['User-ID'], row['ISBN'], ipca, user_item_reduced_train),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Remove NaN predictions\n",
        "test_ratings = test_ratings.dropna(subset=['Predicted'])\n",
        "\n",
        "# Calculate RMSE and MAE\n",
        "rmse = np.sqrt(mean_squared_error(test_ratings['Rating'], test_ratings['Predicted']))\n",
        "mae = mean_absolute_error(test_ratings['Rating'], test_ratings['Predicted'])\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glhJ5_td35GK",
        "outputId": "1f2eb019-903f-43e8-8e69-fdebbf8f45a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_item_reduced_train.shape: (105283, 30)\n",
            "Vt.T.shape: (340556, 30)\n",
            "RMSE: 4.8104\n",
            "MAE: 2.8764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Incremental PCA (acts as Incremental SVD)\n",
        "k = 100  # Number of latent factors\n",
        "batch_size = 100\n",
        "ipca = IncrementalPCA(n_components=k)\n",
        "\n",
        "# Prepare to store results incrementally\n",
        "reduced_chunks_train = []\n",
        "\n",
        "# Fit Incremental PCA on the training set in batches\n",
        "n_samples_train = train_sparse.shape[0]  # Number of users\n",
        "for start in range(0, n_samples_train, batch_size):\n",
        "    end = min(start + batch_size, n_samples_train)\n",
        "    batch = train_sparse[start:end].toarray()  # Convert only the batch to dense\n",
        "\n",
        "    # Skip undersized batches\n",
        "    if batch.shape[0] < k:\n",
        "        print(f\"Skipping undersized batch: {batch.shape[0]} rows, less than k={k}\")\n",
        "        continue\n",
        "\n",
        "    # Incremental fitting\n",
        "    reduced_chunk = ipca.fit_transform(batch) if start == 0 else ipca.transform(batch)\n",
        "    reduced_chunks_train.append(csr_matrix(reduced_chunk))  # Store reduced chunks as sparse matrices\n",
        "\n",
        "# Combine reduced chunks into a sparse matrix\n",
        "user_item_reduced_train = vstack(reduced_chunks_train)\n",
        "\n",
        "# Validate dimensions\n",
        "print(f\"user_item_reduced_train.shape: {user_item_reduced_train.shape}\")\n",
        "print(f\"Vt.T.shape: {ipca.components_.T.shape}\")\n",
        "\n",
        "# Generate predictions for the test set\n",
        "test_ratings['Predicted'] = test_ratings.apply(\n",
        "    lambda row: predict_rating(row['User-ID'], row['ISBN'], ipca, user_item_reduced_train),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Remove NaN predictions\n",
        "test_ratings = test_ratings.dropna(subset=['Predicted'])\n",
        "\n",
        "# Calculate RMSE and MAE\n",
        "rmse = np.sqrt(mean_squared_error(test_ratings['Rating'], test_ratings['Predicted']))\n",
        "mae = mean_absolute_error(test_ratings['Rating'], test_ratings['Predicted'])\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFpWwOHQKZaM",
        "outputId": "87851e47-2e9b-4735-962f-2b9622662c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping undersized batch: 83 rows, less than k=100\n",
            "user_item_reduced_train.shape: (105200, 100)\n",
            "Vt.T.shape: (340556, 100)\n",
            "RMSE: 4.8107\n",
            "MAE: 2.8770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Incremental PCA (acts as Incremental SVD)\n",
        "k = 200  # Number of latent factors\n",
        "batch_size = 200\n",
        "ipca = IncrementalPCA(n_components=k)\n",
        "\n",
        "# Prepare to store results incrementally\n",
        "reduced_chunks_train = []\n",
        "\n",
        "# Fit Incremental PCA on the training set in batches\n",
        "n_samples_train = train_sparse.shape[0]  # Number of users\n",
        "for start in range(0, n_samples_train, batch_size):\n",
        "    end = min(start + batch_size, n_samples_train)\n",
        "    batch = train_sparse[start:end].toarray()  # Convert only the batch to dense\n",
        "\n",
        "    # Skip undersized batches\n",
        "    if batch.shape[0] < k:\n",
        "        print(f\"Skipping undersized batch: {batch.shape[0]} rows, less than k={k}\")\n",
        "        continue\n",
        "\n",
        "    # Incremental fitting\n",
        "    reduced_chunk = ipca.fit_transform(batch) if start == 0 else ipca.transform(batch)\n",
        "    reduced_chunks_train.append(csr_matrix(reduced_chunk))  # Store reduced chunks as sparse matrices\n",
        "\n",
        "# Combine reduced chunks into a sparse matrix\n",
        "user_item_reduced_train = vstack(reduced_chunks_train)\n",
        "\n",
        "# Validate dimensions\n",
        "print(f\"user_item_reduced_train.shape: {user_item_reduced_train.shape}\")\n",
        "print(f\"Vt.T.shape: {ipca.components_.T.shape}\")\n",
        "\n",
        "# Generate predictions for the test set\n",
        "test_ratings['Predicted'] = test_ratings.apply(\n",
        "    lambda row: predict_rating(row['User-ID'], row['ISBN'], ipca, user_item_reduced_train),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Remove NaN predictions\n",
        "test_ratings = test_ratings.dropna(subset=['Predicted'])\n",
        "\n",
        "# Calculate RMSE and MAE\n",
        "rmse = np.sqrt(mean_squared_error(test_ratings['Rating'], test_ratings['Predicted']))\n",
        "mae = mean_absolute_error(test_ratings['Rating'], test_ratings['Predicted'])\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85o2xomaNhSA",
        "outputId": "e57c54b6-4649-47db-b86e-c1c01101d674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping undersized batch: 83 rows, less than k=200\n",
            "user_item_reduced_train.shape: (105200, 200)\n",
            "Vt.T.shape: (340556, 200)\n",
            "RMSE: 4.8104\n",
            "MAE: 2.8770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Incremental PCA (acts as Incremental SVD)\n",
        "k = 50  # Number of latent factors\n",
        "batch_size = 50\n",
        "ipca = IncrementalPCA(n_components=k)\n",
        "\n",
        "# Prepare to store results incrementally\n",
        "reduced_chunks_train = []\n",
        "\n",
        "# Fit Incremental PCA on the training set in batches\n",
        "n_samples_train = train_sparse.shape[0]  # Number of users\n",
        "for start in range(0, n_samples_train, batch_size):\n",
        "    end = min(start + batch_size, n_samples_train)\n",
        "    batch = train_sparse[start:end].toarray()  # Convert only the batch to dense\n",
        "\n",
        "    # Skip undersized batches\n",
        "    if batch.shape[0] < k:\n",
        "        print(f\"Skipping undersized batch: {batch.shape[0]} rows, less than k={k}\")\n",
        "        continue\n",
        "\n",
        "    # Incremental fitting\n",
        "    reduced_chunk = ipca.fit_transform(batch) if start == 0 else ipca.transform(batch)\n",
        "    reduced_chunks_train.append(csr_matrix(reduced_chunk))  # Store reduced chunks as sparse matrices\n",
        "\n",
        "# Combine reduced chunks into a sparse matrix\n",
        "user_item_reduced_train = vstack(reduced_chunks_train)\n",
        "\n",
        "# Validate dimensions\n",
        "print(f\"user_item_reduced_train.shape: {user_item_reduced_train.shape}\")\n",
        "print(f\"Vt.T.shape: {ipca.components_.T.shape}\")\n",
        "\n",
        "# Generate predictions for the test set\n",
        "test_ratings['Predicted'] = test_ratings.apply(\n",
        "    lambda row: predict_rating(row['User-ID'], row['ISBN'], ipca, user_item_reduced_train),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Remove NaN predictions\n",
        "test_ratings = test_ratings.dropna(subset=['Predicted'])\n",
        "\n",
        "# Calculate RMSE and MAE\n",
        "rmse = np.sqrt(mean_squared_error(test_ratings['Rating'], test_ratings['Predicted']))\n",
        "mae = mean_absolute_error(test_ratings['Rating'], test_ratings['Predicted'])\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoAlYJXh6vMg",
        "outputId": "b1e01816-e95f-475e-941d-b11e4837b351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping undersized batch: 33 rows, less than k=50\n",
            "user_item_reduced_train.shape: (105250, 50)\n",
            "Vt.T.shape: (340556, 50)\n",
            "RMSE: 4.8106\n",
            "MAE: 2.8766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Incremental PCA (acts as Incremental SVD)\n",
        "k = 20  # Number of latent factors\n",
        "batch_size = 50\n",
        "ipca = IncrementalPCA(n_components=k)\n",
        "\n",
        "# Prepare to store results incrementally\n",
        "reduced_chunks_train = []\n",
        "\n",
        "# Fit Incremental PCA on the training set in batches\n",
        "n_samples_train = train_sparse.shape[0]  # Number of users\n",
        "for start in range(0, n_samples_train, batch_size):\n",
        "    end = min(start + batch_size, n_samples_train)\n",
        "    batch = train_sparse[start:end].toarray()  # Convert only the batch to dense\n",
        "\n",
        "    # Skip undersized batches\n",
        "    if batch.shape[0] < k:\n",
        "        print(f\"Skipping undersized batch: {batch.shape[0]} rows, less than k={k}\")\n",
        "        continue\n",
        "\n",
        "    # Incremental fitting\n",
        "    reduced_chunk = ipca.fit_transform(batch) if start == 0 else ipca.transform(batch)\n",
        "    reduced_chunks_train.append(csr_matrix(reduced_chunk))  # Store reduced chunks as sparse matrices\n",
        "\n",
        "# Combine reduced chunks into a sparse matrix\n",
        "user_item_reduced_train = vstack(reduced_chunks_train)\n",
        "\n",
        "# Validate dimensions\n",
        "print(f\"user_item_reduced_train.shape: {user_item_reduced_train.shape}\")\n",
        "print(f\"Vt.T.shape: {ipca.components_.T.shape}\")\n",
        "\n",
        "# Generate predictions for the test set\n",
        "test_ratings['Predicted'] = test_ratings.apply(\n",
        "    lambda row: predict_rating(row['User-ID'], row['ISBN'], ipca, user_item_reduced_train),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Remove NaN predictions\n",
        "test_ratings = test_ratings.dropna(subset=['Predicted'])\n",
        "\n",
        "# Calculate RMSE and MAE\n",
        "rmse = np.sqrt(mean_squared_error(test_ratings['Rating'], test_ratings['Predicted']))\n",
        "mae = mean_absolute_error(test_ratings['Rating'], test_ratings['Predicted'])\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgUutkB5_8O7",
        "outputId": "d557f70b-ee62-4070-c04b-11150642e264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_item_reduced_train.shape: (105283, 20)\n",
            "Vt.T.shape: (340556, 20)\n",
            "RMSE: 4.8105\n",
            "MAE: 2.8765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBUp6I8KQPTb"
      },
      "outputs": [],
      "source": [
        "# Get the reduced components (equivalent to SVD outputs)\n",
        "Vt = ipca.components_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for generating book recommendations with collaborative filtering\n",
        "def book_recommendation_collab(user_id, user_mapping, item_mapping, user_item_sparse, user_item_reduced_train, ipca, books, top_n=5):\n",
        "    # Map the user_id to the internal integer ID\n",
        "    if user_id not in user_mapping:\n",
        "        return \"User not found in the data.\"\n",
        "\n",
        "    user_internal_id = user_mapping[user_id]\n",
        "\n",
        "    # Check if the user exists in the reduced matrix\n",
        "    if user_internal_id >= user_item_reduced_train.shape[0]:\n",
        "        return \"User not found in the reduced matrix.\"\n",
        "\n",
        "    # Get the user's reduced latent representation\n",
        "    user_vector = user_item_reduced_train[user_internal_id].toarray()\n",
        "\n",
        "    # Compute similarity scores for all items\n",
        "    item_vectors = ipca.components_.T  # Use components from Incremental PCA\n",
        "    scores = np.dot(item_vectors, user_vector.T).flatten()\n",
        "\n",
        "    # Sort items by score in descending order\n",
        "    top_item_indices = np.argsort(scores)[::-1]\n",
        "\n",
        "    # Reverse map item_mapping to get ISBN from internal integer ID\n",
        "    reverse_item_mapping = {v: k for k, v in item_mapping.items()}\n",
        "\n",
        "    # Get the top N items that the user hasn't already rated\n",
        "    user_rated_items = user_item_sparse[user_internal_id].indices\n",
        "    recommendations = [\n",
        "        (reverse_item_mapping[idx], scores[idx])  # Include both ISBN and score\n",
        "        for idx in top_item_indices\n",
        "        if idx not in user_rated_items\n",
        "    ][:top_n]\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# Example usage\n",
        "recommendations = book_recommendation_collab(\n",
        "    user_id=276737,\n",
        "    user_mapping=user_mapping,\n",
        "    item_mapping=item_mapping,\n",
        "    user_item_sparse=train_sparse,\n",
        "    user_item_reduced_train=user_item_reduced_train,\n",
        "    ipca=ipca,\n",
        "    books=books,\n",
        "    top_n=5\n",
        ")\n",
        "\n",
        "print(f\"Recommended books for user 276737: {recommendations}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZLSyaqHpoWA",
        "outputId": "9097c468-61f4-4e99-bc39-0a7ac1b9eb50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended books for user 276737: [('0440225825', 0.2592933276721045), ('3442136644', 0.2592933276721022), ('3257224281', 0.1079254229366672), ('0440498058', 0.10792542293666657), ('8448034023', 0.07272305782093164)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_book_recommendation(user_id, top_n=5):\n",
        "    # Get recommendations from content-based filtering\n",
        "    content_recommendations = recommend_books_for_user_content(user_id, top_n=top_n)\n",
        "\n",
        "    if isinstance(content_recommendations, str):\n",
        "        # If content-based fails (e.g., user not found), return the error message\n",
        "        return content_recommendations\n",
        "\n",
        "    # Get recommendations from collaborative filtering\n",
        "    collab_recommendations = book_recommendation_collab(\n",
        "        user_id=user_id,\n",
        "        user_mapping=user_mapping,\n",
        "        item_mapping=item_mapping,\n",
        "        user_item_sparse=train_sparse,\n",
        "        user_item_reduced_train=user_item_reduced_train,\n",
        "        ipca=ipca,\n",
        "        books=books,\n",
        "        top_n=top_n\n",
        "    )\n",
        "\n",
        "    if isinstance(collab_recommendations, str):\n",
        "        # If collaborative filtering fails (e.g., user not found), return the error message\n",
        "        return collab_recommendations\n",
        "\n",
        "    # Merge both recommendations on ISBN\n",
        "    content_df = pd.DataFrame(content_recommendations)\n",
        "    content_df.rename(columns={\"Predicted-Rating\": \"Content-Rating\"}, inplace=True)\n",
        "\n",
        "    collab_df = pd.DataFrame(collab_recommendations, columns=[\"ISBN\", \"Collab-Rating\"])\n",
        "\n",
        "    # Merge content and collaborative recommendations\n",
        "    hybrid_df = pd.merge(content_df, collab_df, on=\"ISBN\", how=\"outer\").fillna(0)\n",
        "\n",
        "    # Train linear regression model to combine scores\n",
        "    X = hybrid_df[[\"Content-Rating\", \"Collab-Rating\"]].values\n",
        "    y = np.mean(X, axis=1)  # Simulated target; replace with actual user feedback when available\n",
        "\n",
        "    regressor = LinearRegression()\n",
        "    regressor.fit(X, y)\n",
        "\n",
        "    # Predict hybrid scores\n",
        "    hybrid_df[\"Hybrid-Rating\"] = regressor.predict(X)\n",
        "\n",
        "    # Normalize Hybrid-Rating from [-1, 1] to [1, 10]\n",
        "    hybrid_df[\"Hybrid-Rating\"] = (\n",
        "        1 + (hybrid_df[\"Hybrid-Rating\"] + 1) * 4.5\n",
        "    )\n",
        "\n",
        "    # Sort by hybrid score and select top N recommendations\n",
        "    hybrid_recommendations = hybrid_df.sort_values(by=\"Hybrid-Rating\", ascending=False).head(top_n)\n",
        "\n",
        "    return hybrid_recommendations[[\"ISBN\", \"Hybrid-Rating\"]].reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "user_id = 276726\n",
        "hybrid_recommendations = hybrid_book_recommendation(user_id, top_n=5)\n",
        "\n",
        "print(f\"Top 5 hybrid recommendations for User ID {user_id}:\")\n",
        "print(hybrid_recommendations)\n"
      ],
      "metadata": {
        "id": "yQCHjA-R2PtQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "9cc6fc1b-ef84-424c-a620-1dcfc743ae03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'recommend_books_for_user_content' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-de36d78d56e3>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m276726\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mhybrid_recommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhybrid_book_recommendation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Top 5 hybrid recommendations for User ID {user_id}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-de36d78d56e3>\u001b[0m in \u001b[0;36mhybrid_book_recommendation\u001b[0;34m(user_id, top_n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhybrid_book_recommendation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Get recommendations from content-based filtering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcontent_recommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommend_books_for_user_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_recommendations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'recommend_books_for_user_content' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split with Subset\n",
        "def create_train_test_split(sparse_matrix, test_size=0.2, subset_size=None):\n",
        "    non_zero_indices = np.array(sparse_matrix.nonzero()).T\n",
        "    non_zero_values = sparse_matrix[non_zero_indices[:, 0], non_zero_indices[:, 1]].A1\n",
        "\n",
        "    if subset_size:\n",
        "        non_zero_indices = non_zero_indices[:subset_size]\n",
        "        non_zero_values = non_zero_values[:subset_size]\n",
        "\n",
        "    train_indices, test_indices, train_values, test_values = train_test_split(\n",
        "        non_zero_indices, non_zero_values, test_size=test_size, random_state=42\n",
        "    )\n",
        "\n",
        "    train_data = sp.csr_matrix(\n",
        "        (train_values, (train_indices[:, 0], train_indices[:, 1])), shape=sparse_matrix.shape\n",
        "    )\n",
        "    test_data = sp.csr_matrix(\n",
        "        (test_values, (test_indices[:, 0], test_indices[:, 1])), shape=sparse_matrix.shape\n",
        "    )\n",
        "    return train_data, test_data, test_indices\n",
        "\n",
        "# Create train and test datasets\n",
        "subset_size = 100000\n",
        "train_data, test_data, test_indices = create_train_test_split(user_item_sparse, subset_size=subset_size)\n",
        "\n",
        "# Calculate Baseline Predictions\n",
        "def calculate_baselines(train_data, test_indices):\n",
        "    global_mean = train_data.data.mean()\n",
        "\n",
        "    user_means = np.array(train_data.mean(axis=1)).flatten()\n",
        "    item_means = np.array(train_data.mean(axis=0)).flatten()\n",
        "\n",
        "    global_predictions = np.full(test_indices.shape[0], global_mean)\n",
        "    user_predictions = user_means[test_indices[:, 0]]\n",
        "    item_predictions = item_means[test_indices[:, 1]]\n",
        "\n",
        "    return global_predictions, user_predictions, item_predictions\n",
        "\n",
        "global_predictions, user_predictions, item_predictions = calculate_baselines(train_data, test_indices)\n",
        "\n",
        "# Truncated SVD for Collaborative Filtering\n",
        "def collaborative_filtering(train_data, test_indices, n_components=100):\n",
        "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
        "    train_svd = svd.fit_transform(train_data)\n",
        "\n",
        "    predicted_matrix = np.dot(train_svd, svd.components_)\n",
        "    collab_predictions = predicted_matrix[test_indices[:, 0], test_indices[:, 1]]\n",
        "    return collab_predictions\n",
        "\n",
        "collab_predictions = collaborative_filtering(train_data, test_indices, n_components=100)\n",
        "\n",
        "# Calculate RMSE with Batch Processing\n",
        "def calculate_rmse(actual_ratings, predictions, batch_size=1000):\n",
        "    rmse_batches = []\n",
        "    for i in range(0, len(actual_ratings), batch_size):\n",
        "        actual_batch = actual_ratings[i:i + batch_size]\n",
        "        pred_batch = predictions[i:i + batch_size]\n",
        "        rmse_batches.append(mean_squared_error(actual_batch, pred_batch, squared=False))\n",
        "    return np.mean(rmse_batches)\n",
        "\n",
        "actual_ratings = test_data.data\n",
        "\n",
        "rmse_global = calculate_rmse(actual_ratings, global_predictions)\n",
        "rmse_user = calculate_rmse(actual_ratings, user_predictions)\n",
        "rmse_item = calculate_rmse(actual_ratings, item_predictions)\n",
        "rmse_collab = calculate_rmse(actual_ratings, collab_predictions)\n",
        "\n",
        "# Plot Root mean square\n",
        "def plot_rmse_comparison(models, rmses):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.bar(models, rmses, color=[\"blue\", \"orange\", \"green\", \"red\"])\n",
        "    plt.title(\"RMSE Comparison (Optimized)\", fontsize=16)\n",
        "    plt.ylabel(\"RMSE\", fontsize=12)\n",
        "    plt.xlabel(\"Models\", fontsize=12)\n",
        "    plt.xticks(fontsize=10)\n",
        "    plt.yticks(fontsize=10)\n",
        "    plt.show()\n",
        "\n",
        "models = [\"Global Mean\", \"User Mean\", \"Item Mean\", \"Collaborative\"]\n",
        "rmses = [rmse_global, rmse_user, rmse_item, rmse_collab]\n",
        "\n",
        "plot_rmse_comparison(models, rmses)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qNzesvpD0H4j",
        "outputId": "163e73df-b58a-429e-810f-c5aa70ff8a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}